#Import libraries
import cv2
import re
import os 
from ultralytics import YOLO
from paddleocr import PaddleOCR

#Initial configuration, YOLO model trained for license plate detection and PaddleOCR for OCR. We also include a whitelist pattern to filter unwanted characters.
model = YOLO("  best.pt")
ocr = PaddleOCR(use_textline_orientation=False, lang='es')
whitelist_pattern = re.compile(r'^[A-Z0-9]+$')

# Camera setup
video_source = 2
cap = cv2.VideoCapture(video_source)

if not cap.isOpened():
    print(f"Video source cannot be opened: {video_source}")
    exit()

# Defined resolution setup
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

# Read and print real camera resolution
real_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
real_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
print(f"--- Real camera resolution: {real_width}x{real_height} ---")

#Preprocessing reasonable before giving the image to OCR
def preprocess_for_ocr(img_crop): # Recibe imagen color BGR
    gray = cv2.cvtColor(img_crop, cv2.COLOR_BGR2GRAY) #Convert to gray scale
    gray = cv2.medianBlur(gray, 3) #Median blur to reduce noise
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]
    
    return thresh #Return the image to OCR (black and white)

#Instructions for the user 
print("Initialazing, press --q-- to exit and --s-- to save the image.")

#Main loop for real-time detection and OCR
while True:
    ret, frame = cap.read() #Next frame reading
    if not ret:
        break

    h, w, _ = frame.shape #Obtein width and height of the frame
    results = model(frame) #YOLO model detection

    for result in results:
        index_plates = (result.boxes.cls == 0).nonzero(as_tuple=True)[0] #Filter only "plate" class detections, 0 for YOLO

        for idx in index_plates:
            conf = result.boxes.conf[idx].item() #Probability confidence of the box
            
            if conf > 0.7: #Only if confidence is above 0.7 the license plate will be processed
                xyxy = result.boxes.xyxy[idx].squeeze().tolist()
                x1, y1 = int(xyxy[0]), int(xyxy[1])
                x2, y2 = int(xyxy[2]), int(xyxy[3]) #Box coordinates conversion to int
                
                y1_pad = max(0, y1 - 15)
                y2_pad = min(h, y2 + 15)
                x1_pad = max(0, x1 - 15)
                x2_pad = min(w, x2 + 15) #Adding a 15 pixels margin, but checking image limits
                
                plate_image = frame[y1_pad:y2_pad, x1_pad:x2_pad] #Crop the license plate from the frame

                if plate_image.size == 0: #If the crop is invalid, skip this iteration
                    continue

                

                preprocessed_plate = preprocess_for_ocr(plate_image) #Convert to black and white and apply some filters
                preprocessed_plate_3channel = cv2.cvtColor(preprocessed_plate, cv2.COLOR_GRAY2BGR) #Convert back to 3 channels for PaddleOCR

                #Execute OCR 
                result_ocr = ocr.predict(preprocessed_plate_3channel) 
                print(f"RAW OCR: {result_ocr}")

                output_text = "" #Initialize output text variable
                
                if result_ocr and result_ocr[0]: #If OCR result is valid
                    try:
                        data = result_ocr[0] #Get first result
                        text_list = data['rec_texts'] #List of recognized texts
                        
                        # Filter recognized characters using whitelist:
                        raw_text = ''.join(text_list) 
                        output_text = ''.join([char for char in raw_text if whitelist_pattern.fullmatch(char)])
                        print(f"RAW OCR Text: {raw_text} -> Filtrado: {output_text}")
                        
                    except Exception as e:
                        print(f"Error while processing OCR: {e}")
                        pass
                
                #Show cropped images
                cv2.imshow("Cut license plate (B/N for OCR)", preprocessed_plate)
                
                #Draw bounding box and recognized text on the original frame
                cv2.rectangle(frame, (x1, y1-30), (x1+180, y1), (0, 255, 0), -1)
                cv2.putText(frame, output_text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0 , 0), 2)

    #Show the frame with detections and OCR results
    cv2.imshow("OCR and detection in real time", frame)
     
    #Keyboard inputs handling
    key = cv2.waitKey(1) & 0xFF
    
    # Exit on 'q' key
    if key == ord('q'):
        break
    
    # Save cropped images on 's' key
    if key == ord('s'):
        if 'plate_image' in locals() and plate_image.size > 0:
            cv2.imwrite("debug_cut.png", plate_image)
            cv2.imwrite("debug_cut.png", preprocessed_plate)
            print("--- The images were saved ---")
        else:
            print("--- No license plate to save ---")
#Release resources

#Release camera and close windows
cap.release()
cv2.destroyAllWindows()